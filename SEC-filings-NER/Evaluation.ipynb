{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR=\"Data/\"\n",
    "\n",
    "train_X=np.load(os.path.join(DATA_DIR,\"PP_train_X.npy\"))\n",
    "train_y=np.load(os.path.join(DATA_DIR,\"PP_train_y.npy\"))\n",
    "test_X=np.load(os.path.join(DATA_DIR,\"PP_test_X.npy\"))\n",
    "test_y=np.load(os.path.join(DATA_DIR,\"PP_test_y.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras.models import load_model\n",
    "MAX_LEN=69\n",
    "n_words=4169\n",
    "n_tags=5\n",
    "\n",
    "crf=CRF(n_tags)\n",
    "\n",
    "model=load_model(\"./Models/LSTM-CRF/rmsprop_20200315-172901/rmsprop-24-0.9975.hdf5\",custom_objects={'CRF': crf, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'crf_loss': crf_loss,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'crf_viterbi_accuracy': crf_accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate(model,test_X,test_y):\n",
    "\ttags=['O', 'I-ORG', 'I-LOC', 'I-PER', 'I-MISC']\n",
    "\tpreds=model.predict(test_X,batch_size=32)\n",
    "\tprint(classification_report(np.argmax(test_y,axis=2).flatten(),\n",
    "\t\t\t\t\t\t\tnp.argmax(preds,axis=2).flatten(),\n",
    "\t\t\t\t\t\t\ttarget_names=tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darp_lord/Installs/anaconda3/envs/NLP/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       1.00      1.00      1.00     79947\n",
      "       I-ORG       0.93      0.95      0.94       358\n",
      "       I-LOC       0.89      0.93      0.91       324\n",
      "       I-PER       0.98      0.99      0.99       644\n",
      "      I-MISC       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           1.00     81282\n",
      "   macro avg       0.76      0.77      0.77     81282\n",
      "weighted avg       1.00      1.00      1.00     81282\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       1.00      1.00      1.00     20019\n",
      "       I-ORG       0.75      0.74      0.75        78\n",
      "       I-LOC       0.71      0.65      0.68        60\n",
      "       I-PER       0.98      0.95      0.97       196\n",
      "      I-MISC       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00     20355\n",
      "   macro avg       0.69      0.67      0.68     20355\n",
      "weighted avg       1.00      1.00      1.00     20355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model,train_X,train_y)\n",
    "evaluate(model,test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "def evaluateCRF(model,test_X,test_y):\n",
    "\ttags=['O', 'I-ORG', 'I-LOC', 'I-PER', 'I-MISC']\n",
    "\tpreds=model.predict(test_X,batch_size=32)\n",
    "\tprint(flat_classification_report(np.argmax(test_y,axis=2),\n",
    "\t\t\t\t\t\t\tnp.argmax(preds,axis=2),\n",
    "\t\t\t\t\t\t\tlabels=np.arange(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darp_lord/Installs/anaconda3/envs/NLP/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     79947\n",
      "           1       0.93      0.95      0.94       358\n",
      "           2       0.89      0.93      0.91       324\n",
      "           3       0.98      0.99      0.99       644\n",
      "           4       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           1.00     81282\n",
      "   macro avg       0.76      0.77      0.77     81282\n",
      "weighted avg       1.00      1.00      1.00     81282\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     20019\n",
      "           1       0.75      0.74      0.75        78\n",
      "           2       0.71      0.65      0.68        60\n",
      "           3       0.98      0.95      0.97       196\n",
      "           4       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           1.00     20355\n",
      "   macro avg       0.69      0.67      0.68     20355\n",
      "weighted avg       1.00      1.00      1.00     20355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateCRF(model,train_X,train_y)\n",
    "evaluateCRF(model,test_X,test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
